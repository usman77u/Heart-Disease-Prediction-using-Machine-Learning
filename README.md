Heart Disease Prediction using Machine Learning

Preventing heart diseases is imperative for public health, and the integration of data-driven systems for prediction is crucial. A robust predictive model can revolutionize research and prevention efforts, promoting healthier lives for a larger population. Enter Machine Learning - a game-changer in forecasting heart diseases with remarkable accuracy.

Project Overview:

In this project, I embarked on the analysis of a comprehensive heart disease patient dataset, employing meticulous data processing techniques. The journey unfolded with the training of diverse models, utilizing various algorithms such as KNN, Decision Tree, Random Forest, SVM, Logistic Regression, and more. The entire codebase, encapsulated in a Jupyter notebook, and the dataset were instrumental in the creation of my Kaggle kernel titled 'Binary Classification with Sklearn and Keras'.

Methodology:

The core of the project involved the application of a range of Machine Learning algorithms in Python to predict the presence of heart disease in patients. Tackling this as a classification problem, I leveraged a myriad of input features encompassing a variety of parameters. The target variable, a binary entity, discerned whether heart disease was present or not.

Machine Learning Algorithms Employed:

Logistic Regression (Scikit-learn): Established as a fundamental algorithm, Logistic Regression served as a baseline for comparison with more complex models.

Naive Bayes (Scikit-learn): Leveraging probability-based classification, Naive Bayes contributed its unique approach to the predictive ensemble.

Support Vector Machine (Linear) (Scikit-learn): Harnessing the power of hyperplane separation, SVM (Linear) provided a robust means of classification.

K-Nearest Neighbours (Scikit-learn): Based on proximity, KNN offered a localized perspective in predicting heart diseases.

Decision Tree (Scikit-learn): Decision Tree, a tree-like model, carved its path through the dataset, making decisions at each branch.

Random Forest (Scikit-learn): The ensemble approach of Random Forest amalgamated diverse decision trees, achieving an impressive accuracy of 95%.

XGBoost (Scikit-learn): An optimized implementation of gradient boosting, XGBoost further enriched the predictive capabilities of the model.

Artificial Neural Network with 1 Hidden Layer (Keras): Delving into deep learning, an artificial neural network with a hidden layer brought neural computing to the forefront.
